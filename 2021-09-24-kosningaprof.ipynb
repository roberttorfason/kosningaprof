{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580363b1",
   "metadata": {},
   "source": [
    "# Election Questionnaire (KosningaprÃ³f)\n",
    "> Exploration of the data from the kosningaprof\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [data-science, election, machine-learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab18f4",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The Icelandic parliament election is on the 25. September. Before every election, media outlets set up a quiz/questionnaire where candidates get statements such as *\"Iceland should be a part of NATO\"* and *\"The Icelandic government should put more money into the healthcare system\"* and the candidates answer if they agree/disagree with or are neutral towards the statement. Users can then answer the same questions and figure out which candidates and political parties they are \"closest to\" their political beliefs using the answers to the questions.\n",
    "\n",
    "These are mostly for fun and should only serve as an indicator, but it's an enjoyable process to go through and it's always interesting to see which candidates are \"most similar\" to oneself.\n",
    "\n",
    "As a whole this collection of data, candidates and their answers to a set of questions, is interesting and has a lot of opportunities for some data exploration and the purpose of this post is to take the data from the [RUV quiz](https://www.ruv.is/x21/kosningaprof) explore it and try to answer some questions about it.\n",
    "\n",
    "Similar (and definitely more rigorous) analysis has been done before by people designing the tests and actualluy working with the data, see for example this great thread [here](https://twitter.com/hafsteinneinars/status/1435268582053711881) on this [quiz](https://egkys.is/kosningavitinn/). Since this should not be taken too seriously, the analysis in this post will be more about generating plausible hypthes and doing some ad-hoc analysis.\n",
    "\n",
    "**If you want to fetch the data for yourself, e.g. to run this notebook locally follow the instructions [here](https://github.com/roberttorfason/kosningaprof)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d142ae",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc59af5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:56.958171Z",
     "start_time": "2021-09-24T19:58:56.479855Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36af5b9",
   "metadata": {},
   "source": [
    "Let's load the data, pre-process it and set up some helper objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f0a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:56.988639Z",
     "start_time": "2021-09-24T19:58:56.962790Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results, df_questions = pd.read_csv(\"data/results_2021.csv\"), pd.read_csv(\"data/questions_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf94e800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.032862Z",
     "start_time": "2021-09-24T19:58:56.991102Z"
    }
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "\n",
    "# Pre-processing\n",
    "df_results[\"party\"] = df_results[\"party\"].astype(\"category\")\n",
    "df_results[\"gender\"] = df_results[\"gender\"].astype(\"category\")\n",
    "\n",
    "# Bin the ages. `pd.cut` returns intervals that are annoying to work with so we just use the\n",
    "# left age of each bin e.g. 30 to represent the interval [30, 40)\n",
    "age_binned_series = pd.cut(df_results[\"age\"], bins=[-10, 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], right=False)\n",
    "df_results.insert(df_results.columns.get_loc(\"age\") + 1, \"age_binned\", age_binned_series)\n",
    "\n",
    "df_results[\"age_binned\"] = df_results[\"age_binned\"].map(lambda x: x.left).astype(\"category\")\n",
    "\n",
    "# Most of the analysis centers around the political party so we drop the candiadates that don't have\n",
    "# a party specified\n",
    "df_results = df_results[~df_results[\"party\"].isna()]\n",
    "df_results = df_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce48af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.054382Z",
     "start_time": "2021-09-24T19:58:57.042411Z"
    }
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "cols_questions = [c for c in df_results.columns if c.startswith(\"question_\")]\n",
    "cols_meta = [c for c in df_results.columns if c not in cols_questions]\n",
    "\n",
    "question_id_to_string = dict(zip(df_questions[\"question_number\"], df_questions[\"question\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c5768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T21:34:59.961127Z",
     "start_time": "2021-09-23T21:34:59.951838Z"
    }
   },
   "source": [
    "and take a look at the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa41821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.098409Z",
     "start_time": "2021-09-24T19:58:57.058541Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b64b1",
   "metadata": {},
   "source": [
    "`df_questions` has all the questions and their ids/numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c4a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.167351Z",
     "start_time": "2021-09-24T19:58:57.104106Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d42134",
   "metadata": {},
   "source": [
    "`df_results` represents each candidate in a row, metadata (`age`, `party`, `name`) and the results for all the questions, **where each answer is on the scale from 0-100, 0 meaning that the candidate strongly disagrees with the statement and 100 means the candidate strongly agrees with the statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98061b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.181903Z",
     "start_time": "2021-09-24T19:58:57.175266Z"
    }
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "\"\"\"This text is in a code cell because it's not possible to collapse markdown cells in fastpages\n",
    "\n",
    "Additionally each question in `df_results` has a mapping back to `df_questions` via the column name.\n",
    "Note that the way the questions are indexed there is an easy correspondance between the (numeric) index \n",
    "of each column and `df_questions`. This means that when we later transform the data to numpy arrays, \n",
    "where we don't have named columns, and do something like `x[:, 3]`, it will correspond to `df_questions.iloc[3]` \n",
    "so going back and forth between the data and the actual questions is easy.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef750e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T18:47:31.733824Z",
     "start_time": "2021-09-23T18:47:31.728468Z"
    }
   },
   "source": [
    "# Interactive Histogram of Questions and Answers\n",
    "\n",
    "Below we visualize a histogram of the answers the candidates gave to the questions. The x-axis, Answer Value, is the value of the answer to each question binned and the y-axis is simply the count of those values. Again, these answers are on the scale 0-100, 0 meaning strongly disagree with the statement and 100 strongly agree with the statement. There are also two dropdown menus: One filters by political party and one filters by question so you can see the distribution of answers for each party and each question\n",
    "\n",
    "The questions are ordered by most \"interesting\" to least \"interesting\", where the standard deviation is used as proxy for how interesting it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f062808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.194509Z",
     "start_time": "2021-09-24T19:58:57.187455Z"
    }
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "\"\"\"This text is in a code cell because it's not possible to collapse markdown cells in fastpages\n",
    "\n",
    "Why does standard deviation make sense as a proxy for how interesting a question is?\n",
    "As a very informal argument, thinking about the different scenarios:\n",
    "\n",
    "1. Everyone answers the same or a similar value -> the std. will be low\n",
    "2. The answers are (roughly) uniformly distributed over possible values -> std. will be a \"medium\" value\n",
    "3. If there is a strong split (bi-modal distribution) where candidates either agree or disagree with the\n",
    "   statements -> std. is high\n",
    "\n",
    "Visual inspection of the plots also supports this.\n",
    "\n",
    "One might be inclined to use entropy to measure how interesting a question is, but in that case the ordering\n",
    "would be 1. < 3. < 2., whichis not the desired outcome for this problem, so the std. is more appropriate her.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45035a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.422700Z",
     "start_time": "2021-09-24T19:58:57.199530Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f85e42",
   "metadata": {},
   "source": [
    "We need to pre-process the data for this plot, transforming it from a tall dataframe to a wide dataframe. See a good discussion on why that's useful [here](https://altair-viz.github.io/user_guide/data.html#long-form-vs-wide-form-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff5240",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.480371Z",
     "start_time": "2021-09-24T19:58:57.428578Z"
    }
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "df_results_melt = pd.melt(df_results, id_vars=cols_meta, value_vars=cols_questions)\n",
    "df_results_melt = df_results_melt[[\"party\", \"variable\", \"value\"]]\n",
    "df_results_melt = df_results_melt.rename(columns={\"variable\": \"question\", \"value\": \"Answer Value\"})\n",
    "df_results_melt[\"question\"] = df_results_melt[\"question\"].replace(question_id_to_string)\n",
    "df_results_melt[\"question\"] = df_results_melt[\"question\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576d7f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.493636Z",
     "start_time": "2021-09-24T19:58:57.482480Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions_std = df_results_melt.groupby(\"question\").std().sort_values(\"Answer Value\", ascending=False)\n",
    "questions_sorted = df_questions_std.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b2552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:57.685877Z",
     "start_time": "2021-09-24T19:58:57.495996Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "parties_list = df_results_melt[\"party\"].cat.categories.to_list()\n",
    "questions_list = df_results_melt[\"question\"].cat.categories.to_list()\n",
    "\n",
    "# Highest and lowest entropy/variance parties\n",
    "chart = alt.Chart(df_results_melt).mark_bar().encode(\n",
    "    x=alt.X(f'Answer Value:Q', bin=alt.Bin(extent=[0, 100], step=10), scale=alt.Scale(domain=(0, 100))),\n",
    "    y=alt.Y('count()'),\n",
    "    color='party',\n",
    "    tooltip=['party', alt.Tooltip('count()', title='count')]\n",
    ").interactive()\n",
    "    \n",
    "# A dropdown filter\n",
    "question_dropdown = alt.binding_select(options=[None] + questions_sorted, labels=[\"All\"] + questions_sorted)\n",
    "question_select = alt.selection_single(fields=[\"question\"], bind=question_dropdown, name=\"Question\")\n",
    "\n",
    "chart_filter_question = chart.add_selection(\n",
    "    question_select\n",
    ").transform_filter(\n",
    "    question_select\n",
    ").properties(title=\"Question Result Histogram\")\n",
    " \n",
    "# A dropdown filter\n",
    "party_dropdown = alt.binding_select(options=[None] + parties_list, labels=[\"All\"] + parties_list)\n",
    "party_select = alt.selection_single(fields=[\"party\"], bind=party_dropdown, name=\"Party\")\n",
    "\n",
    "chart_filter_party = chart_filter_question.add_selection(\n",
    "    party_select\n",
    ").transform_filter(\n",
    "    party_select\n",
    ")\n",
    "\n",
    "chart_filter_party"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810bc86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T23:04:00.132451Z",
     "start_time": "2021-09-22T23:04:00.107644Z"
    }
   },
   "source": [
    "# Dimensionality Reduction and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd4aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:34:22.274352Z",
     "start_time": "2021-09-24T07:34:22.271677Z"
    }
   },
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f424ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.431181Z",
     "start_time": "2021-09-24T19:58:57.687895Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from sklearn.decomposition import PCA, NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214999e2",
   "metadata": {},
   "source": [
    "Now we want to plot the data in a lower dimension so we run PCA on the data to get the 2 components that explain most of the variance in the data to be able to plot the candidates and their location in space using these new basis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7874cf",
   "metadata": {},
   "source": [
    "First we pick out the questions from the dataframe and transform the extracted questions to a numpy array to be used with `sklearn` functions. Finally we normalize it to be in the range `[0, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293e62a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.449088Z",
     "start_time": "2021-09-24T19:58:58.437069Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions_only = df_results.filter(like=\"question_\")\n",
    "x = df_questions_only.to_numpy()\n",
    "x = x.astype(float) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fd4b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.464851Z",
     "start_time": "2021-09-24T19:58:58.455707Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from typing import List\n",
    "\n",
    "def numpy_to_dataframe(_x: np.ndarray, _df: pd.DataFrame, cols_to_use: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Concatenate a numpy array with selected columns from a dataframe to be used with altair plotting\"\"\"\n",
    "    df_out = pd.DataFrame(_x)\n",
    "    df_out.columns = df_out.columns.astype(str)\n",
    "    df_out = pd.concat([_df[cols_to_use].reset_index(drop=True), df_out], axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208069d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.495179Z",
     "start_time": "2021-09-24T19:58:58.468003Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "x_pca = pca.fit_transform(x)\n",
    "print(f\"Explained variance of each component {pca.explained_variance_ratio_}.\\n\"\n",
    "      f\"Total explained variance of first 4 components {np.sum(pca.explained_variance_ratio_):.4f}\\n\"\n",
    "      f\"Total explained variance of first 2 components {np.sum(pca.explained_variance_ratio_[:2]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4579db8",
   "metadata": {},
   "source": [
    "The first 2 components only explain roughly 50% of the variance in the data, but the ones that come after individually do not add a lot of explaining power.\n",
    "\n",
    "We plot these components where you can see a breakdown by party and a tooltip overlay indicating which candidate corresponds to which point on the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862135dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.695569Z",
     "start_time": "2021-09-24T19:58:58.498330Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "df_pca = numpy_to_dataframe(x_pca, df_results, cols_meta)\n",
    "df_pca = df_pca.rename(columns={\"0\": \"PCA Component 0\", \"1\": \"PCA Component 1\"})\n",
    "\n",
    "alt.Chart(df_pca).mark_circle(size=60).encode(\n",
    "    x='PCA Component 0',\n",
    "    y='PCA Component 1',\n",
    "    color='party',\n",
    "    tooltip=['party', \"name\"]\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd304861",
   "metadata": {},
   "source": [
    "I don't want to interpret the components for the readers, that is a subjective process, but since the components are a linear combination of the question vectors, we can take a look at which questions contribute most strongly to each component so we can use that to help us interpret them.\n",
    "\n",
    "Note that for negative (red) questions, we need to negate the statement to get the direction that aligns with the components that have positive (green) questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505fcc45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.715324Z",
     "start_time": "2021-09-24T19:58:58.699570Z"
    }
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "df_questions_and_components = pd.DataFrame(\n",
    "    {\"Question\": df_questions[\"question\"], \"Component 0\": pca.components_[0], \"Component 1\": pca.components_[1]}\n",
    ")\n",
    "# We need to sort by the absolute value of each component s.t. we don't disregard components with a negative sign\n",
    "df_questions_and_components[\"Component 0 abs\"] = df_questions_and_components[\"Component 0\"].abs()\n",
    "df_questions_and_components[\"Component 1 abs\"] = df_questions_and_components[\"Component 1\"].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53613449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.736370Z",
     "start_time": "2021-09-24T19:58:58.718870Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "def style_positive_and_negative(v):\n",
    "    if isinstance(v, str):\n",
    "        return None\n",
    "    if v < 0:\n",
    "        return 'color:red;'\n",
    "    else:\n",
    "        return 'color:green;'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acbff92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:11:11.836019Z",
     "start_time": "2021-09-24T08:11:11.827666Z"
    }
   },
   "source": [
    "The top contributing questions for PCA component 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c4156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.875526Z",
     "start_time": "2021-09-24T19:58:58.738763Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "questions_sorted_component_0 = df_questions_and_components.sort_values(by=\"Component 0 abs\", ascending=False)\n",
    "questions_sorted_component_0[[\"Component 0\", \"Question\"]].head(6).style.applymap(style_positive_and_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f3fd3",
   "metadata": {},
   "source": [
    "The top contributing questions for PCA component 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a184948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.919285Z",
     "start_time": "2021-09-24T19:58:58.884568Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "questions_sorted_component_1 = df_questions_and_components.sort_values(by=\"Component 1 abs\", ascending=False)\n",
    "questions_sorted_component_1[[\"Component 1\", \"Question\"]].head(6).style.applymap(style_positive_and_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f28cf60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T07:34:35.953318Z",
     "start_time": "2021-09-24T07:34:35.949296Z"
    }
   },
   "source": [
    "## Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68d7f9",
   "metadata": {},
   "source": [
    "PCA is not the only way to do dimensionality reduction. Another method is non-negative matrix factorization, whose purpose is not necesseraly dimensionality reduction, but the process gives us a natural lower dimensional representation of the candidates **and** the questions in 2 differnt spaces that have a similar structure.\n",
    "\n",
    "Very briefly, NMF seeks to find 2 low rank non-negative matrices $W$ and $H$ such that $W \\cdot H \\approx X$, where $X$ in this case is our data matrix with the shape `(n_candidates, n_questions)`, $W$ has the shape `(n_candidates, n_components)` and $H$ has the shape `(n_components, n_questions)`. For each candidate and each question we get a representation in `n_components` dimensions, in our case we get a 2-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088da39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:58.954795Z",
     "start_time": "2021-09-24T19:58:58.935458Z"
    }
   },
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "\"\"\"This text is in a code cell because it's not possible to collapse markdown cells in fastpages\n",
    "\n",
    "We could also try doing PCA on x.T. The problem is that the basis functions are not interpretable (linear\n",
    "combinations of candidates) and the structure of the space does not necessarily have to correspond to the\n",
    "structure of the space found when doing PCA on the candidates.\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547aeebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:59.019445Z",
     "start_time": "2021-09-24T19:58:58.961471Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=2, init='random', max_iter=400, alpha=0.5, l1_ratio=0.5)\n",
    "W = nmf.fit_transform(x)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e826c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:27:10.139250Z",
     "start_time": "2021-09-24T08:27:10.129425Z"
    }
   },
   "source": [
    "Inspect the shapes of the results as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66308e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:59.037409Z",
     "start_time": "2021-09-24T19:58:59.024344Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "print(f\"x.shape = (n_candidates, n_questions) = {x.shape}\")\n",
    "print(f\"W.shape = (n_candidates, n_components) = {W.shape}\")\n",
    "print(f\"H.shape = (n_components, n_questions) = {H.shape}\")\n",
    "print(f\"(W * H).shape = (n_candidates, n_questions) = {(W @ H).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d0a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:59.148356Z",
     "start_time": "2021-09-24T19:58:59.044760Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "source = pd.DataFrame({\"NMF Component 0\": W[:, 0], \"NMF Component 1\": W[:, 1], \"Party\": df_results[\"party\"], \"Name\": df_results[\"name\"]})\n",
    "\n",
    "chart_results = alt.Chart(source).mark_circle(size=60).encode(\n",
    "    x='NMF Component 0',\n",
    "    y='NMF Component 1',\n",
    "    color='Party',\n",
    "    tooltip=[\"Name\", 'Party']\n",
    ").interactive().properties(title=\"Candidates\")\n",
    "\n",
    "source = pd.DataFrame({\"NMF Component 0\": H.T[:, 0], \"NMF Component 1\": H.T[:, 1], \"Question\": df_questions[\"question\"], \"Number\": range(len(H.T[:, 0]))})\n",
    "\n",
    "chart_questions = alt.Chart(source).mark_circle(size=60).encode(\n",
    "    x='NMF Component 0',\n",
    "    y='NMF Component 1',\n",
    "    tooltip=['Question', 'Number']\n",
    ").interactive().properties(title=\"Questions\")\n",
    "\n",
    "chart_results | chart_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbfddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T08:37:45.694108Z",
     "start_time": "2021-09-24T08:37:45.688947Z"
    }
   },
   "source": [
    "We get a space that seems to capture variability along a single dimension, but the components have a pretty clear meaning. But while the single dimension of variability has a clear interpretation, what does the smaller variability in the tangential dimension of this single dimension (distance from origin) mean?\n",
    "\n",
    "Each element $x_{ij}$ in $X$ is approximated the inner product of a candidate vector and a question vector i.e. $w_i \\cdot h_j$. The higher this inner product is, the higher the value (higher agreement) the resulting answer. If we focus on a question, the interpretation of the radial distance is proportional to the ratio of candidates agree with the statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb861f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T16:55:49.710480Z",
     "start_time": "2021-09-24T16:55:49.701589Z"
    }
   },
   "source": [
    "To support the hypothesis, let's select two questions whose embeddings are close and far away from the origin and look at the histogram they produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a348a3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:59.237180Z",
     "start_time": "2021-09-24T19:58:59.150296Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "question_numbers = [11, 19]\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Filter on those 2 questions\n",
    "idxs = df_results_melt[\"question\"].isin(df_questions.iloc[question_numbers][\"question\"])\n",
    "df_results_melt_filter = df_results_melt[idxs]\n",
    "# A quick hack to get a line break in the question for the plot\n",
    "df_results_melt_filter.loc[:, \"question\"] = df_results_melt_filter[\"question\"].str.replace(\"umsvifum \", \"umsvifum\\n\")\n",
    "df_results_melt_filter = df_results_melt_filter.rename(columns={\"question\": \"Question\"})\n",
    "\n",
    "chart = alt.Chart(df_results_melt_filter).mark_bar().encode(\n",
    "    x=alt.X(f'Answer Value:Q', bin=alt.Bin(extent=[0, 100], step=10), scale=alt.Scale(domain=(0, 100))),\n",
    "    y=alt.Y('count()'),\n",
    "    color='party',\n",
    "    facet=\"Question\",\n",
    "    tooltip=['party', alt.Tooltip('count()', title='count')]\n",
    ").interactive().configure(lineBreak=\"\\n\").properties(width=300)\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73dc08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T15:44:54.210201Z",
     "start_time": "2021-09-24T15:44:54.207563Z"
    }
   },
   "source": [
    "# Interpreting Questions by Classifying Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d326091",
   "metadata": {},
   "source": [
    "Thus far we have not used the \"target\" information i.e. \"party\" or \"age\" in our analysis. Both dimensionality reduction techniques learned a representation of the matrix $X$ without using the target data, except for visualization.\n",
    "\n",
    "Another way to look at the questions is to train a classifier and see which questions are most important to distinguish between the target variables, \"party\" or \"age\". Note that this is not the the same as calculating the variance of the questions as we did before. Even though these are related, a question might have high variance but would not help a classifier separate parties because each party could be divided on the question. This is not very likely, but it could happen in theory to some extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d642f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:59.247496Z",
     "start_time": "2021-09-24T19:58:59.240247Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from typing import Any, Tuple\n",
    "\n",
    "def target_from_col_name(_df: pd.DataFrame, target_name: str, val_to_remove: Any = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    col = _df[target_name]\n",
    "    idxs_to_keep = ~col.isna()\n",
    "    if val_to_remove is not None:\n",
    "        idxs_to_keep = idxs_to_keep & ~(col == val_to_remove)\n",
    "    return col.cat.codes.to_numpy(), idxs_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a8213",
   "metadata": {},
   "source": [
    "Let's look at classifying between the different parties using the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e73def4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:58:59.306792Z",
     "start_time": "2021-09-24T19:58:59.259878Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d571a",
   "metadata": {},
   "source": [
    "We use the default `RandomForestClassifier`. We are not really interested in maximizing performance, we just want to see if there is a signal present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c62a739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T18:22:07.320947Z",
     "start_time": "2021-09-24T18:22:07.315786Z"
    }
   },
   "source": [
    "Filter the data and check the performance performance over 5 splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f267c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:00.488073Z",
     "start_time": "2021-09-24T19:58:59.308673Z"
    }
   },
   "outputs": [],
   "source": [
    "y, idxs = target_from_col_name(df_results, \"party\")\n",
    "x_filter, y_filter = x[idxs, :], y[idxs]\n",
    "\n",
    "cv_results = cross_validate(clf, x_filter, y_filter, cv=5)\n",
    "f\"Accuracy = {np.mean(cv_results['test_score']):.3f}, Std. = {np.std(cv_results['test_score']):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0113a57d",
   "metadata": {},
   "source": [
    "We see there is a strong signal present, as expected since these questions were designed explicitly to differentiate between political parties! We'd expect a random classifier to have an accuracy of $1/11 \\approx 0.09$ (assuming uniform distribution of number of candidates per party for 11 parties) so this is clearly way better.\n",
    "\n",
    "Let's take a look at the questions that are most important for classification between parties using `RandomForestClassifier.feature_importance_`. We don't really care about the numbers themselves, just the rank ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96235bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:00.494409Z",
     "start_time": "2021-09-24T19:59:00.490184Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "def most_important_questions(_clf, _x: np.ndarray, _y: np.ndarray, _df_questions: pd.DataFrame) -> pd.DataFrame:\n",
    "    _clf = _clf.fit(_x, _y)\n",
    "    _df_questions_with_importance = _df_questions.copy()\n",
    "    _df_questions_with_importance[\"importance\"] = _clf.feature_importances_\n",
    "    return _df_questions_with_importance.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96953045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:00.516964Z",
     "start_time": "2021-09-24T19:59:00.496576Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b685bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:00.764338Z",
     "start_time": "2021-09-24T19:59:00.518955Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions_with_importance = most_important_questions(clf, x_filter, y_filter, df_questions)\n",
    "df_questions_with_importance[[\"importance\", \"question\"]].head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90842224",
   "metadata": {},
   "source": [
    "And the least important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957405e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:00.776495Z",
     "start_time": "2021-09-24T19:59:00.766217Z"
    }
   },
   "outputs": [],
   "source": [
    "df_questions_with_importance.tail(6)[[\"importance\", \"question\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc1672",
   "metadata": {},
   "source": [
    "We can do the same but using \"age\" as our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd14bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:01.897218Z",
     "start_time": "2021-09-24T19:59:00.779091Z"
    }
   },
   "outputs": [],
   "source": [
    "y, idxs = target_from_col_name(df_results, \"age_binned\", -10)\n",
    "x_filter, y_filter = x[idxs, :], y[idxs]\n",
    "\n",
    "cv_results = cross_validate(clf, x_filter, y_filter, cv=5)\n",
    "f\"Accuracy = {np.mean(cv_results['test_score']):.3f}, Std. = {np.std(cv_results['test_score']):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4babbaea",
   "metadata": {},
   "source": [
    "The signal is not nearly as strong, but there is still some present. We'd expect a random classifier to have accuracy of $1 / 7 \\approx 0.14$.\n",
    "\n",
    "The most important questions to classify between age groups are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6bb21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:02.201464Z",
     "start_time": "2021-09-24T19:59:01.906722Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide_input\n",
    "df_questions_with_importance = most_important_questions(clf, x_filter, y_filter, df_questions)[[\"importance\", \"question\"]]\n",
    "df_questions_with_importance.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee924aeb",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b8731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T18:55:15.906125Z",
     "start_time": "2021-09-24T18:55:15.900823Z"
    }
   },
   "source": [
    "Hopefully you enjoyed this slightly scattered analysis of this data and learned something new. At least got a chance to play with the interactive plots. There are still a lot of things to explore in the data so I recommend [fetching](https://github.com/roberttorfason/kosningaprof) it for yourself and playing around with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed07250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T19:59:02.208881Z",
     "start_time": "2021-09-24T19:59:02.203572Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# Outliear, density of party, difference between metrics, confusion matrix, mean vs median of question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
